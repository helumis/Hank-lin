{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9b56fcf-130e-4376-b489-936575ca6220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料已保存到 C:\\Users\\User\\Desktop\\學\\大學\\python\\movie_titles_and_urls.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 隨機選擇 User-Agent 防止被網站屏蔽\n",
    "headers = {\n",
    "    'User-Agent': random.choice([\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Step 1: 從 Wikipedia 獲取電影名稱與 Rotten Tomatoes 連結\n",
    "def get_movie_urls_from_wikipedia(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"無法連接到 Wikipedia 頁面, 狀態碼: {response.status_code}\")\n",
    "        return [], []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    movie_urls = []\n",
    "    movie_titles = []\n",
    "    \n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if \"rottentomatoes.com/m/\" in link['href']:\n",
    "            movie_urls.append(link['href'])\n",
    "            movie_titles.append(link.text.strip())\n",
    "    \n",
    "    return movie_titles, movie_urls\n",
    "\n",
    "# Step 2: 將結果存入 CSV 文件\n",
    "def save_to_csv(movie_titles, movie_urls, output_file):\n",
    "    # 創建 DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Movie Title': movie_titles,\n",
    "        'Rotten Tomatoes URL': movie_urls\n",
    "    })\n",
    "    \n",
    "    # 保存到 CSV 文件\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"資料已保存到 {output_file}\")\n",
    "\n",
    "# 執行流程\n",
    "wikipedia_url = \"https://en.wikipedia.org/wiki/List_of_films_with_a_0%25_rating_on_Rotten_Tomatoes\"\n",
    "output_directory = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\"  # 更改為你的輸出路徑# 更改為你的輸出路徑# 更改為你的輸出路徑# 更改為你的輸出路徑# 更改為你的輸出路徑\n",
    "output_file = os.path.join(output_directory, \"movie_titles_and_urls.csv\")\n",
    "\n",
    "# 獲取電影名稱和連結\n",
    "movie_titles, movie_urls = get_movie_urls_from_wikipedia(wikipedia_url)\n",
    "\n",
    "# 保存結果到 CSV\n",
    "if movie_titles and movie_urls:\n",
    "    save_to_csv(movie_titles, movie_urls, output_file)\n",
    "else:\n",
    "    print(\"未能提取到任何電影資料\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f5e6654-67ec-4703-87fd-054868cd5ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在處理電影: \"Staying Alive\"\n",
      "正在處理電影: \"Bolero (1984)\"\n",
      "正在處理電影: \"Police Academy 4: Citizens on Patrol\"\n",
      "正在處理電影: \"Problem Child (1990)\"\n",
      "正在處理電影: \"Highlander 2: The Quickening (1991)\"\n",
      "正在處理電影: \"Return to the Blue Lagoon (1991)\"\n",
      "正在處理電影: \"Folks! (1992)\"\n",
      "正在處理電影: \"Look Who's Talking Now (1993)\"\n",
      "正在處理電影: \"Wagons East! (1994)\"\n",
      "正在處理電影: \"Simon Sez (1999)\"\n",
      "正在處理電影: \"3 Strikes (2000)\"\n",
      "正在處理電影: \"Ballistic: Ecks vs. Sever (2002)\"\n",
      "正在處理電影: \"Killing Me Softly\"\n",
      "正在處理電影: \"Merci Docteur Rey (2002)\"\n",
      "正在處理電影: \"Pinocchio (2002)\"\n",
      "正在處理電影: \"Derailed\"\n",
      "正在處理電影: \"National Lampoon's Gold Diggers (2004)\"\n",
      "正在處理電影: \"Superbabies: Baby Geniuses 2 (2004)\"\n",
      "正在處理電影: \"Constellation\"\n",
      "正在處理電影: \"Redline (2007)\"\n",
      "正在處理電影: \"Scar (2007)\"\n",
      "正在處理電影: \"One Missed Call\"\n",
      "正在處理電影: \"Homecoming\"\n",
      "正在處理電影: \"Stolen\"\n",
      "正在處理電影: \"Transylmania (2009)\"\n",
      "正在處理電影: \"The Nutcracker in 3D (2010)\"\n",
      "正在處理電影: \"Beneath the Darkness\"\n",
      "正在處理電影: \"Dark Tide (2012)\"\n",
      "正在處理電影: \"A Thousand Words\"\n",
      "正在處理電影: \"Left Behind\"\n",
      "正在處理電影: \"The Ridiculous 6 (2015)\"\n",
      "正在處理電影: \"Cabin Fever\"\n",
      "正在處理電影: \"Dark Crimes (2018)\"\n",
      "正在處理電影: \"The Disappointments Room (2016)\"\n",
      "正在處理電影: \"Max Steel (2016)\"\n",
      "正在處理電影: \"Precious Cargo (2016)\"\n",
      "正在處理電影: \"Stratton (2017)\"\n",
      "正在處理電影: \"Gotti\"\n",
      "正在處理電影: \"London Fields (2018)\"\n",
      "正在處理電影: \"The Queen's Corgi (2019)\"\n",
      "正在處理電影: \"John Henry (2020)\"\n",
      "正在處理電影: \"The Last Days of American Crime (2020)\"\n",
      "正在處理電影: \"Hard Kill (2020)\"\n",
      "正在處理電影: \"Jeepers Creepers: Reborn (2022)\"\n",
      "導演資料已保存到 C:\\Users\\User\\Desktop\\學\\大學\\python\\directors_info.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# 隨機選擇 User-Agent 防止被網站屏蔽\n",
    "headers = {\n",
    "    'User-Agent': random.choice([\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Step 1: 爬取導演名稱與導演專業連結\n",
    "def get_director_info_from_rottentomatoes(movie_url):\n",
    "    response = requests.get(movie_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"無法連接到電影頁面: {movie_url}, 狀態碼: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 查找 JSON-LD 數據\n",
    "    script_tag = soup.find('script', type='application/ld+json')\n",
    "    if not script_tag:\n",
    "        print(f\"未找到 JSON-LD 數據: {movie_url}\")\n",
    "        return None\n",
    "\n",
    "    # 解析 JSON 數據\n",
    "    movie_data = json.loads(script_tag.string)\n",
    "\n",
    "    # 提取導演名稱和連結\n",
    "    directors = movie_data.get('director', [])\n",
    "    directors_info = []\n",
    "\n",
    "    for director in directors:\n",
    "        director_name = director.get('name', 'Unknown Director')\n",
    "        director_url = director.get('sameAs', 'Unknown URL')\n",
    "        \n",
    "        # 爬取導演個人資料\n",
    "        director_bio_info = get_director_bio_info(director_url)\n",
    "        if director_bio_info:\n",
    "            director_birthday, director_birthplace, highest_rated, lowest_rated, age = director_bio_info\n",
    "        else:\n",
    "            director_birthday, director_birthplace, highest_rated, lowest_rated, age = 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n",
    "        \n",
    "        directors_info.append({\n",
    "            'Movie Title': movie_data.get('name', 'Unknown Movie'),\n",
    "            'Director Name': director_name,\n",
    "            'Director URL': director_url,\n",
    "            'Birthday': director_birthday,\n",
    "            'Birthplace': director_birthplace,\n",
    "            'Highest Rated': highest_rated,\n",
    "            'Lowest Rated': lowest_rated,\n",
    "            'Age': age\n",
    "        })\n",
    "    \n",
    "    return directors_info\n",
    "\n",
    "# Step 2: 爬取導演的生日、出生地、最高與最低分作品\n",
    "def get_director_bio_info(director_url):\n",
    "    response = requests.get(director_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"無法連接到導演頁面: {director_url}, 狀態碼: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 提取生日\n",
    "    birthday_tag = soup.find('p', {'data-qa': 'celebrity-bio-bday'})\n",
    "    birthday = birthday_tag.text.strip().replace(\"Birthday:\", \"\").strip() if birthday_tag else 'N/A'\n",
    "    # 計算年齡\n",
    "    age = calculate_age(birthday) if birthday != 'N/A' else 'N/A'\n",
    "    \n",
    "    # 提取出生地\n",
    "    birthplace_tag = soup.find('p', {'data-qa': 'celebrity-bio-birthplace'})\n",
    "    birthplace = birthplace_tag.text.strip().replace(\"Birthplace:\", \"\").strip() if birthplace_tag else 'N/A'\n",
    "\n",
    "    # 提取最高與最低分作品\n",
    "    highest_rated_tag = soup.find('p', {'data-qa': 'celebrity-bio-highest-rated'})\n",
    "    highest_rated = highest_rated_tag.find('a').text.strip() if highest_rated_tag and highest_rated_tag.find('a') else 'N/A'\n",
    "\n",
    "    lowest_rated_tag = soup.find('p', {'data-qa': 'celebrity-bio-lowest-rated'})\n",
    "    lowest_rated = lowest_rated_tag.find('a').text.strip() if lowest_rated_tag and lowest_rated_tag.find('a') else 'N/A'\n",
    "    \n",
    "    return birthday, birthplace, highest_rated, lowest_rated, age\n",
    "\n",
    "# 計算年齡\n",
    "def calculate_age(birthday):\n",
    "    try:\n",
    "        birth_date = datetime.strptime(birthday, \"%b %d, %Y\")\n",
    "        today = datetime.now()\n",
    "        return today.year - birth_date.year - ((today.month, today.day) < (birth_date.month, birth_date.day))\n",
    "    except ValueError:\n",
    "        return 'N/A'\n",
    "\n",
    "# Step 3: 從 CSV 中讀取電影 URL，並獲取導演資訊\n",
    "def extract_director_info_from_csv(input_file, output_file):\n",
    "    # 從 CSV 讀取電影標題和連結\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    directors_info = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        movie_title = row['Movie Title']\n",
    "        movie_url = row['Rotten Tomatoes URL']\n",
    "        print(f\"正在處理電影: {movie_title}\")\n",
    "\n",
    "        directors = get_director_info_from_rottentomatoes(movie_url)\n",
    "\n",
    "        if directors:\n",
    "            for director_data in directors:\n",
    "                directors_info.append(director_data)\n",
    "\n",
    "    # 將導演資訊保存到新的 CSV 文件\n",
    "    directors_df = pd.DataFrame(directors_info)\n",
    "    directors_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"導演資料已保存到 {output_file}\")\n",
    "\n",
    "# 執行流程\n",
    "input_csv_file = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\\movie_titles_and_urls.csv\"  # 更改為你的輸入路徑# 更改為你的輸入路徑# 更改為你的輸入路徑# 更改為你的輸入路徑\n",
    "output_csv_file = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\\directors_info.csv\"  # 更改為你的輸出路徑# 更改為你的輸出路徑# 更改為你的輸出路徑\n",
    "\n",
    "# 提取導演資訊並保存\n",
    "extract_director_info_from_csv(input_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2af2577-9ffd-4273-8de4-7ef43e89bddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing director: Sylvester Stallone\n",
      "Processing director: John Derek\n",
      "Processing director: Jim Drake\n",
      "Processing director: Dennis Dugan\n",
      "Processing director: Russell Mulcahy\n",
      "Processing director: William Graham\n",
      "Processing director: Ted Kotcheff\n",
      "Processing director: Tom Ropelewski\n",
      "Processing director: Peter Markle\n",
      "Processing director: Kevin Alyn Elders\n",
      "Processing director: DJ Pooh\n",
      "Processing director: Wych Kaosayananda\n",
      "Processing director: Chen Kaige\n",
      "Processing director: Andrew Litvack\n",
      "Processing director: Roberto Benigni\n",
      "Processing director: Bob Misiorowski\n",
      "Processing director: Gary Preisler\n",
      "Processing director: Bob Clark\n",
      "Processing director: Jordan Walker-Pearlman\n",
      "Processing director: Andy Cheng\n",
      "Processing director: Jed Weintrob\n",
      "Processing director: Éric Valette\n",
      "Processing director: Morgan J. Freeman\n",
      "Processing director: Anders Anderson\n",
      "Processing director: David Hillenbrand\n",
      "Processing director: Scott Hillenbrand\n",
      "Processing director: Andrey Konchalovskiy\n",
      "Processing director: Martin Guigui\n",
      "Processing director: John Stockwell\n",
      "Processing director: Brian Robbins\n",
      "Processing director: Vic Armstrong\n",
      "Processing director: Frank Coraci\n",
      "Processing director: Travis Zariwny\n",
      "Processing director: Alexandros Avranas\n",
      "Processing director: D.J. Caruso\n",
      "Processing director: Stewart Hendler\n",
      "Processing director: Max Adams\n",
      "Processing director: Simon West\n",
      "Processing director: Kevin Connolly\n",
      "Processing director: Mathew Cullen\n",
      "Processing director: Vincent Kesteloot\n",
      "Processing director: Ben Stassen\n",
      "Processing director: Will Forbes\n",
      "Processing director: Olivier Megaton\n",
      "Processing director: Matt Eskandari\n",
      "Processing director: Timo Vuorensola\n",
      "Film and TV data saved to C:\\Users\\User\\Desktop\\學\\大學\\python\\movies_from_directors.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# 隨機 User-Agent 避免被封鎖\n",
    "headers = {\n",
    "    'User-Agent': random.choice([\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 解析 <script> JSON 中的數據\n",
    "def parse_media_scorecard_json(soup):\n",
    "    try:\n",
    "        script_tag = soup.find(\"script\", id=\"media-scorecard-json\", type=\"application/json\")\n",
    "        if script_tag:\n",
    "            json_data = json.loads(script_tag.string)\n",
    "            audience_score = json_data.get(\"audienceScore\", {})\n",
    "            critics_score = json_data.get(\"criticsScore\", {})\n",
    "            return {\n",
    "                \"averageRating\": audience_score.get(\"averageRating\", \"NA\"),\n",
    "                \"bandedRatingCount\": audience_score.get(\"bandedRatingCount\", \"NA\"),\n",
    "                \"likedCount\": audience_score.get(\"likedCount\", \"NA\"),\n",
    "                \"notLikedCount\": audience_score.get(\"notLikedCount\", \"NA\"),\n",
    "                \"reviewCount\": audience_score.get(\"reviewCount\", \"NA\"),\n",
    "                \"score\": audience_score.get(\"score\", \"NA\"),\n",
    "                \"criticsAverageRating\": critics_score.get(\"averageRating\", \"NA\"),\n",
    "                \"criticsReviewCount\": critics_score.get(\"reviewCount\", \"NA\"),\n",
    "                \"criticsScore\": critics_score.get(\"score\", \"NA\")\n",
    "            }\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to decode JSON data\")\n",
    "    return {}\n",
    "\n",
    "# 取得導演的作品列表（包含電影與 TV 劇集）\n",
    "def get_director_filmography(director_url):\n",
    "    response = requests.get(director_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Unable to connect to the page: {director_url}, status code: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    scorecard_data = parse_media_scorecard_json(soup)\n",
    "    filmography = []\n",
    "\n",
    "    for category, label in [('movies', 'Movie'), ('tv', 'TV Show')]:\n",
    "        works = soup.select(f'table[data-qa=\"celebrity-filmography-{category}\"] tbody > tr')\n",
    "\n",
    "        for work in works:\n",
    "            title = work.get('data-title', 'Title not found')\n",
    "\n",
    "            # 判斷 Tomatometer 評分\n",
    "            tomatometer = work.get('data-tomatometer', '')\n",
    "            if tomatometer == \"0\":\n",
    "                tomatometer = \"No Score Yet\" if work.select_one('span.celebrity-filmography__no-score') else \"0%\"\n",
    "\n",
    "            # 判斷觀眾評分\n",
    "            audience_score = work.get('data-audiencescore', '')\n",
    "            if audience_score == \"0\":\n",
    "                audience_score = \"No Score Yet\" if work.select_one('span.celebrity-filmography__no-score') else \"0%\"\n",
    "\n",
    "            # 處理票房和年份數據\n",
    "            box_office = work.get('data-boxoffice', 'Box office not found')\n",
    "            year_raw = work.get('data-appearance-year', work.get('data-year', 'Year not found'))\n",
    "            year = process_year(year_raw)\n",
    "\n",
    "            # 提取導演在作品中的職位\n",
    "            credits = work.find('td', class_='celebrity-filmography__credits').text.strip() if work.find('td', class_='celebrity-filmography__credits') else 'Role not found'\n",
    "            \n",
    "            # 添加數據到 filmography 列表，並包含電影或 TV 劇集類別\n",
    "            filmography.append({\n",
    "                'title': title,\n",
    "                'year': year,\n",
    "                'tomatometer': tomatometer,\n",
    "                'audience_score': audience_score,\n",
    "                'box_office': box_office,\n",
    "                'credits': credits,\n",
    "                'category': label,\n",
    "                **scorecard_data  # 合併 scorecard 數據\n",
    "            })\n",
    "    \n",
    "    return filmography\n",
    "\n",
    "def process_year(year_raw):\n",
    "    \"\"\" 處理年份數據，包括單一年份或範圍值。 \"\"\"\n",
    "    if isinstance(year_raw, list):\n",
    "        return \", \".join(year_raw)\n",
    "    if year_raw.startswith(\"[\") and year_raw.endswith(\"]\"):\n",
    "        year_range = year_raw.strip(\"[]\").split('-')\n",
    "        start_year = year_range[0]\n",
    "        end_year = year_range[1] if len(year_range) > 1 else start_year\n",
    "        return f\"{start_year}-{end_year}\"\n",
    "    return year_raw\n",
    "\n",
    "# 提取數據並儲存到 CSV\n",
    "def extract_movies_from_directors(input_file, output_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    all_movies = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        director_name = row['Director Name']\n",
    "        director_url = row['Director URL']\n",
    "        print(f\"Processing director: {director_name}\")\n",
    "\n",
    "        movies = get_director_filmography(director_url)\n",
    "        \n",
    "        for movie in movies:\n",
    "            movie['Director Name'] = director_name\n",
    "            all_movies.append(movie)\n",
    "\n",
    "    movies_df = pd.DataFrame(all_movies)\n",
    "    movies_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Film and TV data saved to {output_file}\")\n",
    "\n",
    "# 執行程序\n",
    "input_csv_file = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\\directors_info.csv\"\n",
    "output_csv_file = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\\movies_from_directors.csv\"\n",
    "extract_movies_from_directors(input_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42a5b153-b2ee-4a68-9ac3-b97f1612a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for director: Sylvester Stallone\n",
      "Scraping data for director: John Derek\n",
      "Scraping data for director: Jim Drake\n",
      "Scraping data for director: Dennis Dugan\n",
      "Scraping data for director: Russell Mulcahy\n",
      "Scraping data for director: William Graham\n",
      "Scraping data for director: Ted Kotcheff\n",
      "Scraping data for director: Tom Ropelewski\n",
      "Scraping data for director: Peter Markle\n",
      "Scraping data for director: Kevin Alyn Elders\n",
      "Scraping data for director: DJ Pooh\n",
      "Scraping data for director: Wych Kaosayananda\n",
      "Scraping data for director: Chen Kaige\n",
      "Scraping data for director: Andrew Litvack\n",
      "Scraping data for director: Roberto Benigni\n",
      "Scraping data for director: Bob Misiorowski\n",
      "Scraping data for director: Gary Preisler\n",
      "Scraping data for director: Bob Clark\n",
      "Scraping data for director: Jordan Walker-Pearlman\n",
      "Scraping data for director: Andy Cheng\n",
      "Scraping data for director: Jed Weintrob\n",
      "Scraping data for director: Éric Valette\n",
      "Scraping data for director: Morgan J. Freeman\n",
      "Scraping data for director: Anders Anderson\n",
      "Scraping data for director: David Hillenbrand\n",
      "Scraping data for director: Scott Hillenbrand\n",
      "Scraping data for director: Andrey Konchalovskiy\n",
      "Scraping data for director: Martin Guigui\n",
      "Scraping data for director: John Stockwell\n",
      "Scraping data for director: Brian Robbins\n",
      "Scraping data for director: Vic Armstrong\n",
      "Scraping data for director: Frank Coraci\n",
      "Scraping data for director: Travis Zariwny\n",
      "Scraping data for director: Alexandros Avranas\n",
      "Scraping data for director: D.J. Caruso\n",
      "Scraping data for director: Stewart Hendler\n",
      "Scraping data for director: Max Adams\n",
      "Scraping data for director: Simon West\n",
      "Scraping data for director: Kevin Connolly\n",
      "Scraping data for director: Mathew Cullen\n",
      "Scraping data for director: Vincent Kesteloot\n",
      "Scraping data for director: Ben Stassen\n",
      "Scraping data for director: Will Forbes\n",
      "Scraping data for director: Olivier Megaton\n",
      "Scraping data for director: Matt Eskandari\n",
      "Scraping data for director: Timo Vuorensola\n",
      "Data saved to C:\\Users\\User\\Desktop\\學\\大學\\python\\directors_movies_details.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Headers for requests to avoid blocking\n",
    "headers = {\n",
    "    'User-Agent': random.choice([\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
    "    ])\n",
    "}\n",
    "\n",
    "def parse_movie_page(url):\n",
    "    \"\"\"Scrape movie-specific information from each individual movie URL.\"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        # Extracting JSON from <script> for audience and critics' scores\n",
    "        scorecard_script = soup.find(\"script\", id=\"media-scorecard-json\", type=\"application/json\")\n",
    "        scorecard_data = json.loads(scorecard_script.string) if scorecard_script else {}\n",
    "\n",
    "        # Extracting synopsis\n",
    "        synopsis_tag = soup.select_one('[data-qa=\"synopsis-value\"]')\n",
    "        synopsis = synopsis_tag.get_text(strip=True) if synopsis_tag else \"Synopsis not found\"\n",
    "        \n",
    "        # Extracting other movie information\n",
    "        movie_info = {}\n",
    "        for item in soup.select('div.category-wrap'):\n",
    "            label = item.select_one('[data-qa=\"item-label\"]').get_text(strip=True)\n",
    "            value = \", \".join([i.get_text(strip=True) for i in item.select('[data-qa=\"item-value\"]')])\n",
    "            movie_info[label] = value\n",
    "\n",
    "        # Merging extracted data\n",
    "        movie_data = {\n",
    "            'audience_score': scorecard_data.get(\"audienceScore\", {}).get(\"score\", \"NA\"),\n",
    "            'critics_score': scorecard_data.get(\"criticsScore\", {}).get(\"score\", \"NA\"),\n",
    "            'synopsis': synopsis,\n",
    "            **movie_info\n",
    "        }\n",
    "        return movie_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse movie page {url}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_director_movies(director_url):\n",
    "    \"\"\"Retrieve list of movies directed by a director from their filmography page.\"\"\"\n",
    "    response = requests.get(director_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to access {director_url}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    movies = []\n",
    "\n",
    "    for work in soup.select('[data-qa=\"celebrity-filmography-movies-trow\"]'):\n",
    "        title = work.get('data-title', 'Unknown title')\n",
    "        year = work.get('data-year', 'Unknown year')\n",
    "        movie_url = \"https://www.rottentomatoes.com\" + work.select_one('a')['href']\n",
    "        \n",
    "        movie_data = parse_movie_page(movie_url)\n",
    "        movies.append({'title': title, 'year': year, 'movie_url': movie_url, **movie_data})\n",
    "\n",
    "    return movies\n",
    "\n",
    "def extract_all_director_data(input_file, output_file):\n",
    "    \"\"\"Read CSV of directors, collect movie data for each, and save results to a new CSV.\"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    all_movies = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        director_url = row['Director URL']\n",
    "        print(f\"Scraping data for director: {row['Director Name']}\")\n",
    "        \n",
    "        movies = get_director_movies(director_url)\n",
    "        for movie in movies:\n",
    "            movie['Director Name'] = row['Director Name']\n",
    "            all_movies.append(movie)\n",
    "\n",
    "    movies_df = pd.DataFrame(all_movies)\n",
    "    movies_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_csv_file = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\\directors_info.csv\"\n",
    "output_csv_file = r\"C:\\Users\\User\\Desktop\\學\\大學\\python\\movies_details.csv\"\n",
    "extract_all_director_data(input_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8f9c5-e800-4c52-bfb5-ac174c7913d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
